{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model  \n",
    "from keras.layers import *\n",
    " \n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Nadam\n",
    "from keras.utils import Sequence\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.csv',\n",
       " 'test_index_sample.csv',\n",
       " 'train_index_sample.csv',\n",
       " 'valid_index_sample.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "data, data_train, data_valid, data_test = read_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day', 'hour', 'duration_std', 'time_betw_std']\n",
      "['case_applicationtype', 'case_loangoal', 'accepted', 'resource']\n",
      "['case_requestedamount_std', 'creditscore_std', 'firstwithdrawalamount_std', 'monthlycost_std', 'numberofterms_std', 'offeredamount_std']\n"
     ]
    }
   ],
   "source": [
    "time_feat = ['day', 'hour',  'duration_std', 'time_betw_std']\n",
    "cat_feat = ['case_applicationtype', 'case_loangoal', 'accepted', 'resource']\n",
    "num_feat = ['case_requestedamount_std', 'creditscore_std','firstwithdrawalamount_std', 'monthlycost_std', 'numberofterms_std', 'offeredamount_std']\n",
    "\n",
    "feat_dic = {}\n",
    "feat_dic['time_feat'] = time_feat\n",
    "feat_dic['cat_feat'] = cat_feat\n",
    "feat_dic['num_feat'] = num_feat\n",
    "\n",
    "print(time_feat)\n",
    "print(cat_feat)\n",
    "print(num_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers = get_helpers(data, feat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_base_name = lambda config: ' '.join([\"{}-{}\".format(k,v) for k, v in config.items() if not k.startswith('_')])\n",
    "config_file_template = lambda config: 'inter_latent50' + config_base_name(config) + ' {epoch:02d} {loss:.5f} {val_loss:.5f}.h5'\n",
    "\n",
    "model_configurations = [ \n",
    "    {'output_dim': int(data_train.append(data_valid)['length'].max()), 'HUnits': units, 'dropout': do, 'lr': lr} for units, do, lr in product([40], [0], [0.002]) #output dim should be max sequence length\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(output_dim=25, dropout_rate=0.2, learning_rate = 0.002, latent_dim=40, helpers_dic=helpers):\n",
    "    \n",
    "    print('drop:', dropout_rate)\n",
    "           \n",
    "    inp_trace = Input(shape=(output_dim, helpers_dic['trace_helper']['vocab_size']), name='Xtrace')\n",
    "    inp_day = Input(shape=(output_dim, 1), name='Xday')\n",
    "    inp_hour = Input(shape=(output_dim, 1), name='Xhour')\n",
    "    inp_duration = Input(shape=(output_dim, 1), name='Xduration_std')\n",
    "    inp_time = Input(shape=(output_dim, 1), name='Xtime_betw_std')\n",
    "    \n",
    "    inp_application = Input(shape=(output_dim, 1), name='Xcase_applicationtype')\n",
    "    inp_lgoal = Input(shape=(output_dim, 1), name='Xcase_loangoal')\n",
    "    inp_reqamount = Input(shape=(output_dim, 1), name='Xcase_requestedamount_std')\n",
    "    \n",
    "    inp_accepted = Input(shape=(output_dim, 1), name='Xaccepted')\n",
    "    inp_resource = Input(shape=(output_dim, 1), name='Xresource')\n",
    "    inp_creditscore = Input(shape=(output_dim, 1), name='Xcreditscore_std')\n",
    "    inp_firstwd = Input(shape=(output_dim, 1), name='Xfirstwithdrawalamount_std')\n",
    "    inp_mcost = Input(shape=(output_dim, 1), name='Xmonthlycost_std')\n",
    "    inp_nterms = Input(shape=(output_dim, 1), name='Xnumberofterms_std')\n",
    "    inp_oamount = Input(shape=(output_dim, 1), name='Xofferedamount_std')\n",
    "            \n",
    "    emb_hour = Embedding(output_dim = round(1.6 * (helpers_dic['time_helpers']['hour']['size']-1)**0.56), input_dim=helpers_dic['time_helpers']['hour']['size'], name='EmbHour')(Flatten()(inp_hour))\n",
    "    emb_day = Embedding(output_dim =  round(1.6 * (helpers_dic['time_helpers']['day']['size']-1)**0.56), input_dim=helpers_dic['time_helpers']['day']['size'], name='EmbDay')(Flatten()(inp_day))\n",
    "    emb_application = Embedding(output_dim =  round(1.6 * (helpers_dic['cat_helpers']['case_applicationtype']['size']-1)**0.56), input_dim=helpers_dic['cat_helpers']['case_applicationtype']['size'], name='EmbApplication')(Flatten()(inp_application))\n",
    "    emb_lgoal = Embedding(output_dim =  round(1.6 * (helpers_dic['cat_helpers']['case_loangoal']['size']-1)**0.56), input_dim=helpers_dic['cat_helpers']['case_loangoal']['size'], name='EmbLgoal')(Flatten()(inp_lgoal))\n",
    "    emb_resource = Embedding(output_dim =  round(1.6 * (helpers_dic['cat_helpers']['resource']['size']-1)**0.56), input_dim=helpers_dic['cat_helpers']['resource']['size'], name='EmbResource')(Flatten()(inp_resource))\n",
    "    emb_accepted = Embedding(output_dim =  round(1.6 * (helpers_dic['cat_helpers']['accepted']['size']-1)**0.56), input_dim=helpers_dic['cat_helpers']['accepted']['size'], name='EmbAccepted')(Flatten()(inp_accepted))\n",
    "    \n",
    "    \n",
    "    merged = concatenate([(inp_trace), \n",
    "                          (emb_day), (emb_hour),(inp_duration), (inp_time),\n",
    "                          (emb_application), (emb_lgoal), (inp_reqamount),\n",
    "                          (emb_resource), (inp_creditscore), (emb_accepted), (inp_firstwd), (inp_mcost), (inp_nterms), (inp_oamount)], name='concat_input')\n",
    "        \n",
    "    \n",
    "    LSTM1 = Bidirectional(LSTM(latent_dim, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, recurrent_dropout = dropout_rate, dropout = dropout_rate), name='LSTMshared1')\n",
    "    outputs1 = LSTM1(merged)\n",
    "    \n",
    "    b1 = BatchNormalization()(outputs1)\n",
    "    \n",
    "    LSTM_trace1 = Bidirectional(LSTM(latent_dim,  implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, recurrent_dropout = dropout_rate, dropout = dropout_rate), name='LSTMtrace1') #maybe do return seq false\n",
    "    outputs2_1a = LSTM_trace1(b1)\n",
    "    \n",
    "    b2_1a = BatchNormalization()(outputs2_1a)\n",
    "    \n",
    "    LSTM_time1 = Bidirectional(LSTM(latent_dim, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, recurrent_dropout = dropout_rate, dropout = dropout_rate), name='LSTMtime1') #maybe do return seq false\n",
    "    outputs2_2a = LSTM_time1(b1)\n",
    "    \n",
    "    b2_2a = BatchNormalization()(outputs2_2a)\n",
    "       \n",
    "    output_trace = TimeDistributed(Dense(helpers_dic['trace_helper']['vocab_size'], kernel_initializer='glorot_uniform', activation='softmax'), name='trace_out')(b2_1a)\n",
    "    \n",
    "    output_time = TimeDistributed(Dense(1, kernel_initializer='he_uniform'), name='time_out_nolr')(b2_2a) #used to be name time_out_nolr with LeakyRelu\n",
    "    output_time = TimeDistributed(PReLU(), name='time_out')(output_time)\n",
    "        \n",
    "    model = Model(inputs=[inp_trace, \n",
    "                          inp_day, inp_hour, inp_duration, inp_time,\n",
    "                          inp_application, inp_lgoal, inp_reqamount, \n",
    "                          inp_resource, inp_creditscore, inp_accepted, inp_firstwd, inp_mcost, inp_nterms, inp_oamount], \n",
    "                  outputs=[output_time, output_trace])\n",
    "    \n",
    "\n",
    "    opt = Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)#clipvalue=3\n",
    "    \n",
    "    \n",
    "    model.compile(loss={'trace_out':'categorical_crossentropy', 'time_out':'mae'}, optimizer=opt) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, epochs=500, feat_dic = feat_dic, helpers_dic=helpers):\n",
    "    training_generator = BagDataGenerator(data_train,  config['output_dim'], feat_dic, helpers_dic)\n",
    "    validation_generator = BagDataGenerator(data_valid,  config['output_dim'], feat_dic, helpers_dic)\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(config_file_template(config), \n",
    "                                       monitor='val_loss', verbose=0, \n",
    "                                       save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=16, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0) #was factor 0.5 and 0.01\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=59)\n",
    "    \n",
    "   \n",
    "    output_dim = config['output_dim']\n",
    "    dropout = config['dropout']\n",
    "    lr = config['lr']\n",
    "    latent_dim = config['HUnits']\n",
    "    \n",
    "    \n",
    "    print('*** Now trainining:\\n', config_base_name(config))\n",
    "    \n",
    "    model = get_model(output_dim, dropout, lr, latent_dim)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    training = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=epochs, verbose=2,\n",
    "                        class_weight=None,\n",
    "                        use_multiprocessing = False,\n",
    "                        callbacks=[model_checkpoint, early_stopping, lr_reducer]) \n",
    "    return training \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Now trainining:\n",
      " output_dim-63 HUnits-40 dropout-0 lr-0.002\n",
      "drop: 0\n",
      "WARNING:tensorflow:From D:\\Users\\u0126338\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Xday (InputLayer)               (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xhour (InputLayer)              (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xcase_applicationtype (InputLay (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xcase_loangoal (InputLayer)     (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xresource (InputLayer)          (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xaccepted (InputLayer)          (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 63)           0           Xday[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 63)           0           Xhour[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 63)           0           Xcase_applicationtype[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 63)           0           Xcase_loangoal[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 63)           0           Xresource[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 63)           0           Xaccepted[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Xtrace (InputLayer)             (None, 63, 29)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbDay (Embedding)              (None, 63, 5)        40          flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "EmbHour (Embedding)             (None, 63, 9)        225         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Xduration_std (InputLayer)      (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xtime_betw_std (InputLayer)     (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbApplication (Embedding)      (None, 63, 2)        6           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "EmbLgoal (Embedding)            (None, 63, 7)        105         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Xcase_requestedamount_std (Inpu (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbResource (Embedding)         (None, 63, 26)       3848        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Xcreditscore_std (InputLayer)   (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EmbAccepted (Embedding)         (None, 63, 3)        12          flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Xfirstwithdrawalamount_std (Inp (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xmonthlycost_std (InputLayer)   (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xnumberofterms_std (InputLayer) (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Xofferedamount_std (InputLayer) (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat_input (Concatenate)      (None, 63, 89)       0           Xtrace[0][0]                     \n",
      "                                                                 EmbDay[0][0]                     \n",
      "                                                                 EmbHour[0][0]                    \n",
      "                                                                 Xduration_std[0][0]              \n",
      "                                                                 Xtime_betw_std[0][0]             \n",
      "                                                                 EmbApplication[0][0]             \n",
      "                                                                 EmbLgoal[0][0]                   \n",
      "                                                                 Xcase_requestedamount_std[0][0]  \n",
      "                                                                 EmbResource[0][0]                \n",
      "                                                                 Xcreditscore_std[0][0]           \n",
      "                                                                 EmbAccepted[0][0]                \n",
      "                                                                 Xfirstwithdrawalamount_std[0][0] \n",
      "                                                                 Xmonthlycost_std[0][0]           \n",
      "                                                                 Xnumberofterms_std[0][0]         \n",
      "                                                                 Xofferedamount_std[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "LSTMshared1 (Bidirectional)     (None, 63, 80)       41600       concat_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 63, 80)       320         LSTMshared1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTMtime1 (Bidirectional)       (None, 63, 80)       38720       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 63, 80)       320         LSTMtime1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "LSTMtrace1 (Bidirectional)      (None, 63, 80)       38720       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_out_nolr (TimeDistributed) (None, 63, 1)        81          batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 63, 80)       320         LSTMtrace1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_out (TimeDistributed)      (None, 63, 1)        1           time_out_nolr[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "trace_out (TimeDistributed)     (None, 63, 29)       2349        batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 126,667\n",
      "Trainable params: 126,187\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\u0126338\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "for config in model_configurations:\n",
    "    training = train_model(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
